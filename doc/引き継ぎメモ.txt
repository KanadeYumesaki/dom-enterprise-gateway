---

## 1. 引き継ぎメモ（v1.3・P1/P2含めた完全版）

### 1-1. 現状サマリ（2025-12 時点）

* リポジトリ:

  * GitHub: `KanadeYumesaki/dom-enterprise-gateway`
  * バックエンド（`backend/`）の FastAPI サーバは **全テスト 53 passed, 1 skipped** まで到達済み。
  * スキップは RAG のストリーミングテスト（`test_stream_rag_response`）のみで、`TESTING_NOTES.md` に理由を明記済み。
* 実装されている主な機能（P0 相当）：

  * OIDC ベースの認証・認可（テナント＆ RBAC）
  * コアチャット（DOM Orchestrator 経由のストリーミング応答 / IC-5 ライト形式）
  * LangChain v1 ベースの RAG（pgvector 前提の設計）
  * メモリ（短期 / Structured / Episodic）
  * セッション単位のファイル添付（Ephemeral RAG 用）
  * 簡易フィードバック（👍/👎 + コメント）
  * ユーザー設定 / 一部管理系エンドポイントの土台

### 1-2. P0 / P1 / P2 の位置付け

#### P0（PoC）＝「今の実装がカバーしている世界」

* 目的：

  * **エンタープライズ向けチャット + RAG + メモリ** の「縦に細いけど全部入り」の PoC。
* 主なスコープ：

  * FastAPI Backend 中心の BFF
  * OAuth2/OIDC 認証 & テナント分離
  * IC-5 *ライト*（Decision / Why / Next 3 Actions）形式の回答
  * シングルターン RAG（LangChain v1 / pgvector）
  * ファイル添付 → Ephemeral RAG
  * メモリ保存と `/reset` インバリアント
  * ユーザー設定 / ヘルプコンテンツの土台

#### P1 = v1 本番

> ユーザーから見て「ちゃんとした社内プロダクト」になっている状態。

* LlmClient 抽象を本格運用：

  * Main: その時点でベストな **Gemini / GPT / Claude** のいずれかをテナント設定で選択可能。
  * Helper: **ローカル DeepSeek 小モデル**（コスト節約・軽量タスク用）を想定。
* RAG & メモリ運用を「現場で使えるレベル」に昇格：

  * ナレッジ登録フロー（管理画面からの登録 / バージョン管理 / ソフトデリート）。
  * StructuredMemory 検索、EpisodicMemory 検索の UI と API 拡充。
* IC-5 フル形式の導入（FR-CHAT-3）：

  * 重要な問いでは、Options / Risks を含めた **意思決定支援テンプレート** を返す。
* ガバナンス UI：

  * テナント単位で「使用モデル / RAG ソース / メモリ保持方針 / レート制御」を設定する管理画面。
* AgentOps & メトリクス：

  * AgentOps ダッシュボード（FR-FEED-2）、基本的なリクエスト数・トークン量・エラー率の可視化。
* セキュリティ / ライフサイクル：

  * Tool 権限ガバナンス、テナント終了・データ削除ポリシー、モデルアップデート時のリグレッションテスト。

#### P2 = v1.5〜v2

> 「AI ソリューションアーキテクト案件でも戦える」レベルの高度版。

* PSI 風自己改善ループ

  * Structure/Integration Meister を本格実装し、ログ・フィードバック・メモリから **自動でプロンプト/ポリシー改善** を回す。
* マルチエージェント拡張

  * Critic / Reviewer / Governance / Router などのエージェントを追加し、

    * 回答品質チェック
    * ポリシー違反検知
    * モデルルーティング（コスト/精度/レイテンシのバランス）
      を行う。
* ポリシー変更ワークフロー

  * 「ガバナンス担当がポリシーを propose → 審査 → テスト → 本番反映」というワークフローを GUI + GitOps 風に実現。
* Explainability / トレース強化

  * 「どのエージェントが・どのナレッジを・どのプロンプトで使ったか」の追跡をしやすくし、
  * EU AI Act を意識した透明性と監査性の向上。

---

### 1-3. 重要ドキュメントと役割

* `requirements_p0_core_chat.md`

  * P0〜P1 の機能要件・非機能要件の「一次ソース」。
  * RAG / メモリ / ファイル / Reset など、仕様レベルの期待値はここを参照。
* `DOM Enterprise Gateway.txt`

  * システム全体像・アーキテクチャ・FR/NFR のまとめ。
  * P1/P2 以降に伸ばすときの「地図」として使える。
* `help_content_outline.md`

  * ユーザー向けヘルプセンター構成案。
  * 将来、フロント実装時の UX リファレンスとして重要。
* `AI駆動開発_共通ガイドライン.md`

  * 今回の「AI 任せ」スタイルのベースとなる運用・Git・ドキュメントポリシー。

---

### 1-4. 次に着手しやすいタスク候補

1. **Backend P1-first**

   * `LlmClient` 抽象を実コードに落とし込み、今は 1 種類になっている LLM 呼び出しを Main/Helper 切り替え可能な形にする。
   * AgentOps 用のログ・メトリクスを最低限入れておく。

2. **Frontend PoC（薄く広く）**

   * Angular でチャット画面 + セッション一覧 + 簡易設定画面だけ先に作る。
   * Research モード・IC-5 表示などは P0 要件に忠実に実装。

3. **P1 スコープの「薄切り」**

   * テナント設定と LLM プロファイル切り替えだけ先にやる、など
   * 「運用すると痛いところ」から順に実装していく。

---

## 2. 「開発スタイル」メモ – AI任せを強みに変えるために

ポートフォリオとして見せるときに大事なのは：

> 「丸投げ」ではなく **AI を「協調開発者」として使い倒している** という構図

を、具体的に説明できることだと思います。

### 2-1. 開発スタイルの基本コンセプト

1. **人間が「境界条件」と「安全装置」を設計**

   * 仕様（requirements / DOM doc）を AI と一緒に詰めるが、最終決定は人間。
   * Git / テスト / PoC のスコープなど「壊れないための枠組み」は人間が設計。
2. **実装・修正は AI にガンガン投げる**

   * FastAPI のエンドポイント、サービス層、テストコード修正などは基本 AI/エージェントに任せる。
   * ただし、**必ずテストで検証** し、通らなければ差し戻し。
3. **AI を「バグ修正係」としても活用**

   * エラー log をそのまま渡し、「原因の特定 → 修正差分 → テスト実行」までを自動化。
4. **人間は「レビュー & モニタリング」役**

   * 生成されたコード・ドキュメントを読んで、

     * 仕様からズレてないか
     * 破壊的変更をしていないか
       を確認し、必要に応じて微修正 or 差し戻し。

---

### 2-2. 機能・レイヤごとの「AI vs 人間」の役割分担

※ 厳密な行数ではなく、「誰が主導したか」の粒度で整理しています。

#### A. 要件定義・アーキテクチャ

* **AI 主導（人間レビュー）**

  * `requirements_p0_core_chat.md` の初期ドラフト
  * `DOM Enterprise Gateway.txt` の全体像 / FR / NFR の構成
* **人間主導**

  * P0/P1/P2 の優先順位づけ・実際にどこまで作るかの判断
  * 「PoC は Backend 中心」「フロントは薄くor後回し」などの現実的スコープ設定
  * 「AI ソリューションアーキテクトとして見せたい」というポートフォリオ戦略

#### B. バックエンド実装（FastAPI / サービス / リポジトリ）

* **AI 主導**

  * 初期のコードスキャフォールド（cc-sdd 産物）
  * Antigravity/Gemini エージェントによる：

    * import エラー修正
    * 循環依存解消（`get_dom_orchestrator_service` の定義順変更 など）
    * AuthService / RAG サービスの細かいバグ修正
    * `TESTING_NOTES.md` の作成
* **人間主導**

  * WSL + Poetry + venv のセットアップ / 実行環境準備
  * エージェントに投げる前の「保険」設計：

    * 対象ディレクトリの限定（`backend/app` だけなど）
    * Git コミットでロールバック可能にしておく
  * 生成コードが仕様どおりかのレビュー（ときどき手動修正）

#### C. テストコード・品質保証

* **AI 主導**

  * 既存テストを読んで、サービス・依存関係をテストが通るように修正する流れ
  * `test_auth_service.py` のモック / JWT / JWK 周りのエラー修正
* **人間主導**

  * `poetry run pytest app/tests` の実行と、失敗した時のログ提示
  * 「テストは全部通る状態をゴールとする」という開発ポリシーの決定
  * スキップせざるを得ないテスト（RAG ストリーミング）の妥協ライン判断

#### D. ドキュメント・README / TESTING_NOTES

* **AI 主導**

  * README の初期案、TESTING_NOTES の構成・文章作成
  * 引き継ぎメモ（本メモ含む）のドラフト作成
* **人間主導**

  * 実際の開発体験を踏まえた修正（エラー内容 / 環境依存の補足など）
  * 「ポートフォリオとしてどう見せたいか」の観点からの調整

#### E. 開発プロセス・Git 運用

* **AI 主導**

  * `AI駆動開発_共通ガイドライン.md` による Git/レビュー/ドキュメント運用のテンプレ提案
* **人間主導**

  * 実際のブランチ運用・コミット単位をどうするかの最終決定
  * 将来チーム開発に発展させるときの「自分なりのルール追加」

---

### 2-3. ポートフォリオでの見せ方サンプル

文章のイメージも少し置いておきます。Qiita や職務経歴書にそのまま近い形で使えるような文脈です。

> * DOM Enterprise Gateway では、仕様策定・アーキテクチャ設計・安全装置の設計（テスト / Git / 環境）は人間が担当し、
>   実装・バグ修正・ドキュメントドラフトなど反復作業を AI エージェントに任せる **「AI 協調開発」スタイル** を採用しました。
> * 特にバックエンドでは、あえて壊れた状態のスキャフォールドコードを AI に渡し、
>   エージェントにテスト駆動で ImportError や循環依存を解消させるプロセスを構築しました。
> * 開発者としては、
>
>   * スコープ定義（P0/P1/P2）、
>   * ガードレール設計（どこまで AI に触らせるか）、
>   * テストとコードレビューによる品質ゲート
>     を担当しつつ、AI の出力をプラットフォームとして活用しています。

---

もしよければ、この「開発スタイル」部分だけを切り出して、

* Qiita の自己紹介
* GitHub の `README` 下部の「Architecture / Development Style」
  にも再利用すると、「AI 任せを武器にしている」感がかなり伝わりやすくなると思います。

このメモをベースに、次スレッドでは「じゃあ P1 のどこからやるか」「フロント PoC をどう切るか」みたいな、より具体的なタスク分解に入っていけます。
